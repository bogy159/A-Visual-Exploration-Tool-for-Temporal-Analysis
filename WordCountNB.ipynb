{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from itertools import chain\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "newStopWords = {}\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "sball = SnowballStemmer('english')\n",
    "spor = PorterStemmer()\n",
    "slan = LancasterStemmer()\n",
    "\n",
    "import time\n",
    "import Filter as fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading():\n",
    "\n",
    "    def readCSV(item):\n",
    "        data = pd.read_csv(item, dtype={0: int}, index_col=0, encoding='latin-1')\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "\n",
    "    restaurants = readCSV('static/revSam.csv')\n",
    "    \n",
    "    return restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(dataset, number):\n",
    "    dataPart = dataset.sample(n=number, random_state=1)\n",
    "    \n",
    "    return dataPart\n",
    "\n",
    "dataPart = randomize(reading(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(item, granulation):\n",
    "    \n",
    "    item = item.loc[:, ['date','text']]\n",
    "    item = item.sort_values('date', ascending = True)\n",
    "    if granulation == \"Year\":\n",
    "        item['time'] = pd.to_datetime(item.date).dt.year\n",
    "    elif (granulation == \"Month\"):\n",
    "        item['time'] = pd.to_datetime(item.date)\n",
    "        item['time'] = item.time.map(lambda x: x.strftime('%Y-%m'))\n",
    "    result = item.loc[:, ['time','text']]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterTime(item,time):\n",
    "    \n",
    "    result = item.copy()\n",
    "    indexNames = item[item['time'] != time].index\n",
    "    result.drop(indexNames , inplace=True)\n",
    "    result = result.rename(columns={'text': str(time)})\n",
    "    \n",
    "    return result[str(time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenCount(item, top, getLemma, phrases):\n",
    "    \n",
    "    global newStopWords\n",
    "    if (phrases == \"True\" or phrases == \"true\"):\n",
    "        allWords = item.apply(phrasesTB).tolist() \n",
    "        #Here we flatten the list\n",
    "        allWords = list(chain.from_iterable(allWords))\n",
    "    else:        \n",
    "        tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "        allWords = item.apply(tokenizer.tokenize).tolist()        \n",
    "        allWords = list(chain.from_iterable(allWords)) \n",
    "        if getLemma == \"True\" or getLemma == \"true\":\n",
    "            print(\"Just keep lemming!\")\n",
    "            allWords = lemmatizingSpacy(allWords, True)\n",
    "        elif getLemma == \"stem\" or getLemma == \"Stem\":\n",
    "            print(\"Just keep snowing\")\n",
    "            allWords = stemmingSnowball(allWords, True)\n",
    "        elif getLemma == \"port\" or getLemma == \"Port\":\n",
    "            print(\"Just keep porting\")\n",
    "            allWords = stemmingPorter(allWords, True)\n",
    "        elif getLemma == \"lanc\" or getLemma == \"Lanc\":\n",
    "            print(\"Just keep lancaster\")\n",
    "            allWords = stemmingLancaster(allWords, True)\n",
    " \n",
    "    allWordExceptStopDist = nltk.FreqDist(w.lower() for w in allWords if (w.lower() not in stopwords) and (w.lower() not in newStopWords)) \n",
    "\n",
    "    wordCount = pd.Series(allWordExceptStopDist).to_frame(item.name)\n",
    "    wordCount.sort_values(by=[item.name], inplace = True, ascending=False)\n",
    "    if (int(top)> wordCount.size):\n",
    "        top = wordCount.size\n",
    "    result = wordCount.head(int(top)).reset_index()\n",
    "    result = result.rename(columns={result.columns[0]: 'Words: ' + str(item.name)})\n",
    "    result = result.rename(columns={result.columns[1]: 'Count: ' + str(item.name)})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(item, top, getLemma, phrases, common):\n",
    "    \n",
    "    if (phrases == \"True\" or phrases == \"true\"):\n",
    "        mid = wWeighting(item, phrases, common)    \n",
    "    elif (getLemma == \"True\" or getLemma == \"true\"):\n",
    "        \n",
    "        print(\"Just keep lemming!\")\n",
    "        item = item.apply(removeSWSentance, args=[True])\n",
    "        item = item.apply(lemmatizingSpacy, args=[False])\n",
    "        mid = wWeighting(item, phrases, common)    \n",
    "    elif getLemma == \"stem\" or getLemma == \"Stem\":\n",
    "        print(\"Just keep snowing\")\n",
    "        item = item.apply(removeSWSentance, args=[True])\n",
    "        item = item.apply(stemmingSnowball, args=[False])\n",
    "        mid = wWeighting(item, phrases, common)  \n",
    "    else:\n",
    "        item = item.apply(removeSWSentance, args=[False])\n",
    "        mid = wWeighting(item, phrases, common)    \n",
    "        \n",
    "    wordCount = pd.Series(mid).to_frame(item.name)\n",
    "    wordCount.sort_values(by=[item.name], inplace = True, ascending=False)    \n",
    "    \n",
    "    if (int(top)> wordCount.size):\n",
    "        top = wordCount.size\n",
    "    result = wordCount.head(int(top)).reset_index()\n",
    "    result = result.rename(columns={result.columns[0]: 'Words: ' + str(item.name)})\n",
    "    result = result.rename(columns={result.columns[1]: 'Count: ' + str(item.name)})\n",
    "    result = result.round({result.columns[1]: 2})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frameY(item, common, top, getLemma, frequency, phrases):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    global newStopWords\n",
    "    newStopWords = {}\n",
    "    start = item.rename(columns={'text': \"Overall\"})\n",
    "    \n",
    "    if frequency == \"True\" or frequency == \"true\":\n",
    "        start = tf_idf(start[\"Overall\"], top, getLemma, phrases, common)\n",
    "    else:\n",
    "        start = tokenCount(start[\"Overall\"], top, getLemma, phrases)\n",
    "    \n",
    "    if common == \"False\" or common == \"false\":\n",
    "        newStopWords = set(start[\"Words: Overall\"].str.lower())\n",
    "    \n",
    "    uniqueTime = item.time.unique()   \n",
    "    DF_list = [filterTime(item, i) for i in uniqueTime]\n",
    "    if frequency == \"True\" or frequency == \"true\":\n",
    "        result = pd.concat([tf_idf(i, top, getLemma, phrases, common) for i in DF_list], axis=1)\n",
    "    else:\n",
    "        result = pd.concat([tokenCount(i, top, getLemma, phrases) for i in DF_list], axis=1)\n",
    "    \n",
    "    result = pd.concat([start,result], axis=1)\n",
    "    \n",
    "    result.index+=1\n",
    "    result.index.names = ['Place']\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(\"frameY :\" + str(t1-t0))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizingSpacy(item, isList):\n",
    "    \n",
    "    document = spacy.tokens.Doc(nlp.vocab, words=item)\n",
    "    if(isList):        \n",
    "        result = [w.lemma_ for w in document]\n",
    "    else:\n",
    "        result = \" \".join([w.lemma_ for w in document])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmingSnowball(item, isList):\n",
    "    \n",
    "    #ps = nltk.stem.SnowballStemmer('english')  \n",
    "    ps = sball\n",
    "    if(isList):        \n",
    "        result = [ps.stem(w) for w in item]\n",
    "    else:\n",
    "        result = \" \".join([ps.stem(w) for w in item])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmingLancaster(item, isList):\n",
    "    \n",
    "    #ps = nltk.stem.lancaster.LancasterStemmer() \n",
    "    ps = slan\n",
    "    if(isList):        \n",
    "        result = [ps.stem(w) for w in item]\n",
    "    else:\n",
    "        result = \" \".join([ps.stem(w) for w in item])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmingPorter(item, isList):\n",
    "    \n",
    "    #ps = nltk.stem.lancaster.LancasterStemmer() \n",
    "    ps = spor\n",
    "    if(isList):        \n",
    "        result = [ps.stem(w) for w in item]\n",
    "    else:\n",
    "        result = \" \".join([ps.stem(w) for w in item])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSWSentance(sentence, isList):\n",
    "    global newStopWords\n",
    "    \n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    allWords = tokenizer.tokenize(sentence)\n",
    "    \n",
    "    if(isList):\n",
    "        result = [word for word in allWords if (word.lower() not in stopwords) and (word.lower() not in newStopWords) and (word != \"-PRON-\")]\n",
    "    else:\n",
    "        result = \" \".join([word for word in allWords if (word.lower() not in stopwords) and (word.lower() not in newStopWords) and (word != \"-PRON-\")])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wWeighting(item, phrases, common):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    if (phrases == \"True\" or phrases == \"true\"):\n",
    "        if (common == \"False\" or common == \"false\"):\n",
    "            vectorizer = TfidfVectorizer(ngram_range=(2,5), stop_words = 'english', preprocessor=remove_stop_phrases)\n",
    "        else:\n",
    "            vectorizer = TfidfVectorizer(ngram_range=(2,5), stop_words = 'english')\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    matrix = vectorizer.fit_transform(item).todense()\n",
    "    # transform the matrix to a pandas df\n",
    "    matrix = pd.DataFrame(matrix, columns=vectorizer.get_feature_names())\n",
    "    # sum over each document (axis=0)\n",
    "    top_words = matrix.sum(axis=0).sort_values(ascending=False)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(\"wWeighting - \" + item.name + \" :\" + str(t1-t0))\n",
    "    \n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_phrases(doc):    \n",
    "    global newStopWords\n",
    "    #print(newStopWords)\n",
    "    stop_phrases = newStopWords\n",
    "    \n",
    "    for phrase in stop_phrases:\n",
    "        doc = re.sub(phrase, \"\", doc, flags=re.IGNORECASE)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrasesTB(text):\n",
    "    value = TextBlob(text).noun_phrases\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(item, boolean, top, granulation, getLemma, frequency, phrases):\n",
    "    mid = prepareData(item, granulation)\n",
    "    result = frameY(mid, boolean, top, getLemma, frequency, phrases)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>ccur</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>444610</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-25</td>\n",
       "      <td>Located next to the Eiffel tower and across th...</td>\n",
       "      <td>\"Mon Ami Gabi\"</td>\n",
       "      <td>89109</td>\n",
       "      <td>7328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439720</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>My wife made reservations for a party of 10. W...</td>\n",
       "      <td>\"Mon Ami Gabi\"</td>\n",
       "      <td>89109</td>\n",
       "      <td>7328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439719</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-09-22</td>\n",
       "      <td>This place has over 3000+ yelp reviews so we d...</td>\n",
       "      <td>\"Mon Ami Gabi\"</td>\n",
       "      <td>89109</td>\n",
       "      <td>7328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439718</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-21</td>\n",
       "      <td>We made a reservation for 845 we show up at 84...</td>\n",
       "      <td>\"Mon Ami Gabi\"</td>\n",
       "      <td>89109</td>\n",
       "      <td>7328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439716</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>OH MY GOD. \\r\\r\\r\\nThis place was so delicious...</td>\n",
       "      <td>\"Mon Ami Gabi\"</td>\n",
       "      <td>89109</td>\n",
       "      <td>7328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444856</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>This is my 2nd time visiting Mon Ami Gabi and ...</td>\n",
       "      <td>\"Mon Ami Gabi\"</td>\n",
       "      <td>89109</td>\n",
       "      <td>7328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444855</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>From Wikipedia, \"Snail is a common name for al...</td>\n",
       "      <td>\"Mon Ami Gabi\"</td>\n",
       "      <td>89109</td>\n",
       "      <td>7328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444841</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>As a belated birthday present, I wanted to tak...</td>\n",
       "      <td>\"Mon Ami Gabi\"</td>\n",
       "      <td>89109</td>\n",
       "      <td>7328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444830</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-03-23</td>\n",
       "      <td>Une brasserie vraiment franÃ§ais, on the Las V...</td>\n",
       "      <td>\"Mon Ami Gabi\"</td>\n",
       "      <td>89109</td>\n",
       "      <td>7328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444831</td>\n",
       "      <td>4JNXUYY8wbaaDmk3BPzlWw</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-09-13</td>\n",
       "      <td>We came here for dinner.  The onion soup was e...</td>\n",
       "      <td>\"Mon Ami Gabi\"</td>\n",
       "      <td>89109</td>\n",
       "      <td>7328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  stars        date  \\\n",
       "index                                               \n",
       "444610  4JNXUYY8wbaaDmk3BPzlWw      4  2015-07-25   \n",
       "439720  4JNXUYY8wbaaDmk3BPzlWw      5  2015-09-13   \n",
       "439719  4JNXUYY8wbaaDmk3BPzlWw      5  2013-09-22   \n",
       "439718  4JNXUYY8wbaaDmk3BPzlWw      1  2015-01-21   \n",
       "439716  4JNXUYY8wbaaDmk3BPzlWw      5  2013-06-01   \n",
       "...                        ...    ...         ...   \n",
       "444856  4JNXUYY8wbaaDmk3BPzlWw      5  2016-04-16   \n",
       "444855  4JNXUYY8wbaaDmk3BPzlWw      4  2011-01-05   \n",
       "444841  4JNXUYY8wbaaDmk3BPzlWw      4  2011-01-07   \n",
       "444830  4JNXUYY8wbaaDmk3BPzlWw      4  2014-03-23   \n",
       "444831  4JNXUYY8wbaaDmk3BPzlWw      2  2014-09-13   \n",
       "\n",
       "                                                     text            name  \\\n",
       "index                                                                       \n",
       "444610  Located next to the Eiffel tower and across th...  \"Mon Ami Gabi\"   \n",
       "439720  My wife made reservations for a party of 10. W...  \"Mon Ami Gabi\"   \n",
       "439719  This place has over 3000+ yelp reviews so we d...  \"Mon Ami Gabi\"   \n",
       "439718  We made a reservation for 845 we show up at 84...  \"Mon Ami Gabi\"   \n",
       "439716  OH MY GOD. \\r\\r\\r\\nThis place was so delicious...  \"Mon Ami Gabi\"   \n",
       "...                                                   ...             ...   \n",
       "444856  This is my 2nd time visiting Mon Ami Gabi and ...  \"Mon Ami Gabi\"   \n",
       "444855  From Wikipedia, \"Snail is a common name for al...  \"Mon Ami Gabi\"   \n",
       "444841  As a belated birthday present, I wanted to tak...  \"Mon Ami Gabi\"   \n",
       "444830  Une brasserie vraiment franÃ§ais, on the Las V...  \"Mon Ami Gabi\"   \n",
       "444831  We came here for dinner.  The onion soup was e...  \"Mon Ami Gabi\"   \n",
       "\n",
       "        postal_code  ccur  \n",
       "index                      \n",
       "444610        89109  7328  \n",
       "439720        89109  7328  \n",
       "439719        89109  7328  \n",
       "439718        89109  7328  \n",
       "439716        89109  7328  \n",
       "...             ...   ...  \n",
       "444856        89109  7328  \n",
       "444855        89109  7328  \n",
       "444841        89109  7328  \n",
       "444830        89109  7328  \n",
       "444831        89109  7328  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = fil.main('', '', \"01.01.2010\", \"31.12.2016\", \"\", \"\", \"\").head(1000)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just keep snowing\n",
      "Just keep snowing\n",
      "Just keep snowing\n",
      "Just keep snowing\n",
      "Just keep snowing\n",
      "Just keep snowing\n",
      "Just keep snowing\n",
      "Just keep snowing\n",
      "frameY :3.3381097316741943\n",
      "Svurshi: 3.348048210144043\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words: Overall</th>\n",
       "      <th>Count: Overall</th>\n",
       "      <th>Words: 2010</th>\n",
       "      <th>Count: 2010</th>\n",
       "      <th>Words: 2011</th>\n",
       "      <th>Count: 2011</th>\n",
       "      <th>Words: 2012</th>\n",
       "      <th>Count: 2012</th>\n",
       "      <th>Words: 2013</th>\n",
       "      <th>Count: 2013</th>\n",
       "      <th>Words: 2014</th>\n",
       "      <th>Count: 2014</th>\n",
       "      <th>Words: 2015</th>\n",
       "      <th>Count: 2015</th>\n",
       "      <th>Words: 2016</th>\n",
       "      <th>Count: 2016</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Place</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>715</td>\n",
       "      <td>good</td>\n",
       "      <td>66</td>\n",
       "      <td>good</td>\n",
       "      <td>97</td>\n",
       "      <td>good</td>\n",
       "      <td>88</td>\n",
       "      <td>food</td>\n",
       "      <td>127</td>\n",
       "      <td>food</td>\n",
       "      <td>135</td>\n",
       "      <td>great</td>\n",
       "      <td>129</td>\n",
       "      <td>food</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>food</td>\n",
       "      <td>712</td>\n",
       "      <td>steak</td>\n",
       "      <td>55</td>\n",
       "      <td>food</td>\n",
       "      <td>82</td>\n",
       "      <td>great</td>\n",
       "      <td>84</td>\n",
       "      <td>good</td>\n",
       "      <td>127</td>\n",
       "      <td>great</td>\n",
       "      <td>125</td>\n",
       "      <td>food</td>\n",
       "      <td>122</td>\n",
       "      <td>good</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>great</td>\n",
       "      <td>678</td>\n",
       "      <td>great</td>\n",
       "      <td>53</td>\n",
       "      <td>french</td>\n",
       "      <td>71</td>\n",
       "      <td>food</td>\n",
       "      <td>79</td>\n",
       "      <td>great</td>\n",
       "      <td>120</td>\n",
       "      <td>place</td>\n",
       "      <td>120</td>\n",
       "      <td>good</td>\n",
       "      <td>117</td>\n",
       "      <td>great</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>order</td>\n",
       "      <td>563</td>\n",
       "      <td>order</td>\n",
       "      <td>47</td>\n",
       "      <td>restaur</td>\n",
       "      <td>71</td>\n",
       "      <td>order</td>\n",
       "      <td>70</td>\n",
       "      <td>place</td>\n",
       "      <td>106</td>\n",
       "      <td>good</td>\n",
       "      <td>112</td>\n",
       "      <td>order</td>\n",
       "      <td>117</td>\n",
       "      <td>servic</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>place</td>\n",
       "      <td>536</td>\n",
       "      <td>food</td>\n",
       "      <td>45</td>\n",
       "      <td>great</td>\n",
       "      <td>67</td>\n",
       "      <td>steak</td>\n",
       "      <td>67</td>\n",
       "      <td>veri</td>\n",
       "      <td>100</td>\n",
       "      <td>steak</td>\n",
       "      <td>104</td>\n",
       "      <td>servic</td>\n",
       "      <td>110</td>\n",
       "      <td>veri</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>steak</td>\n",
       "      <td>532</td>\n",
       "      <td>place</td>\n",
       "      <td>39</td>\n",
       "      <td>order</td>\n",
       "      <td>67</td>\n",
       "      <td>servic</td>\n",
       "      <td>64</td>\n",
       "      <td>steak</td>\n",
       "      <td>92</td>\n",
       "      <td>time</td>\n",
       "      <td>95</td>\n",
       "      <td>veri</td>\n",
       "      <td>93</td>\n",
       "      <td>order</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>servic</td>\n",
       "      <td>526</td>\n",
       "      <td>french</td>\n",
       "      <td>36</td>\n",
       "      <td>veri</td>\n",
       "      <td>66</td>\n",
       "      <td>veri</td>\n",
       "      <td>57</td>\n",
       "      <td>vega</td>\n",
       "      <td>88</td>\n",
       "      <td>vega</td>\n",
       "      <td>95</td>\n",
       "      <td>steak</td>\n",
       "      <td>83</td>\n",
       "      <td>place</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>veri</td>\n",
       "      <td>507</td>\n",
       "      <td>like</td>\n",
       "      <td>35</td>\n",
       "      <td>like</td>\n",
       "      <td>65</td>\n",
       "      <td>place</td>\n",
       "      <td>55</td>\n",
       "      <td>order</td>\n",
       "      <td>88</td>\n",
       "      <td>order</td>\n",
       "      <td>91</td>\n",
       "      <td>restaur</td>\n",
       "      <td>83</td>\n",
       "      <td>steak</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>vega</td>\n",
       "      <td>464</td>\n",
       "      <td>time</td>\n",
       "      <td>34</td>\n",
       "      <td>vega</td>\n",
       "      <td>61</td>\n",
       "      <td>french</td>\n",
       "      <td>53</td>\n",
       "      <td>servic</td>\n",
       "      <td>85</td>\n",
       "      <td>servic</td>\n",
       "      <td>88</td>\n",
       "      <td>place</td>\n",
       "      <td>82</td>\n",
       "      <td>restaur</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>time</td>\n",
       "      <td>438</td>\n",
       "      <td>view</td>\n",
       "      <td>33</td>\n",
       "      <td>patio</td>\n",
       "      <td>58</td>\n",
       "      <td>vega</td>\n",
       "      <td>50</td>\n",
       "      <td>french</td>\n",
       "      <td>74</td>\n",
       "      <td>view</td>\n",
       "      <td>78</td>\n",
       "      <td>vega</td>\n",
       "      <td>76</td>\n",
       "      <td>time</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words: Overall  Count: Overall Words: 2010  Count: 2010 Words: 2011  \\\n",
       "Place                                                                       \n",
       "1               good             715        good           66        good   \n",
       "2               food             712       steak           55        food   \n",
       "3              great             678       great           53      french   \n",
       "4              order             563       order           47     restaur   \n",
       "5              place             536        food           45       great   \n",
       "6              steak             532       place           39       order   \n",
       "7             servic             526      french           36        veri   \n",
       "8               veri             507        like           35        like   \n",
       "9               vega             464        time           34        vega   \n",
       "10              time             438        view           33       patio   \n",
       "\n",
       "       Count: 2011 Words: 2012  Count: 2012 Words: 2013  Count: 2013  \\\n",
       "Place                                                                  \n",
       "1               97        good           88        food          127   \n",
       "2               82       great           84        good          127   \n",
       "3               71        food           79       great          120   \n",
       "4               71       order           70       place          106   \n",
       "5               67       steak           67        veri          100   \n",
       "6               67      servic           64       steak           92   \n",
       "7               66        veri           57        vega           88   \n",
       "8               65       place           55       order           88   \n",
       "9               61      french           53      servic           85   \n",
       "10              58        vega           50      french           74   \n",
       "\n",
       "      Words: 2014  Count: 2014 Words: 2015  Count: 2015 Words: 2016  \\\n",
       "Place                                                                 \n",
       "1            food          135       great          129        food   \n",
       "2           great          125        food          122        good   \n",
       "3           place          120        good          117       great   \n",
       "4            good          112       order          117      servic   \n",
       "5           steak          104      servic          110        veri   \n",
       "6            time           95        veri           93       order   \n",
       "7            vega           95       steak           83       place   \n",
       "8           order           91     restaur           83       steak   \n",
       "9          servic           88       place           82     restaur   \n",
       "10           view           78        vega           76        time   \n",
       "\n",
       "       Count: 2016  \n",
       "Place               \n",
       "1              122  \n",
       "2              108  \n",
       "3              100  \n",
       "4               95  \n",
       "5               84  \n",
       "6               83  \n",
       "7               76  \n",
       "8               73  \n",
       "9               72  \n",
       "10              70  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "nakraq = main(filtered, \"true\", \"10\", \"Year\", \"stem\", \"false\", \"false\")\n",
    "end = time.time()\n",
    "print(\"Svurshi: \" + str(end - start))\n",
    "nakraq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"musn't\", 'antonym', 'uglify', 'our', 'ugly']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "class AntonymReplacer(object):\n",
    "\tdef replace(self, word, pos=None):\n",
    "\t\t#Returns the antonym of a word, but only if there is no ambiguity.\n",
    "\t\tantonyms = set()\n",
    "\t\t\n",
    "\t\tfor syn in wordnet.synsets(word, pos=pos):\n",
    "\t\t\tfor lemma in syn.lemmas():\n",
    "\t\t\t\tfor antonym in lemma.antonyms():\n",
    "\t\t\t\t\tantonyms.add(antonym.name())\n",
    "\t\tprint(antonyms)\n",
    "\t\tif len(antonyms) == 1:\n",
    "\t\t\treturn antonyms.pop()\n",
    "\t\telif len(antonyms) > 1:\n",
    "\t\t\treturn antonyms.pop()\n",
    "\t\telse:\n",
    "\t\t\treturn None\n",
    "\t\n",
    "\tdef replace_negations(self, sent):\n",
    "\t\t#Try to replace negations with antonyms in the tokenized sentence.\n",
    "\t\ti, l = 0, len(sent)\n",
    "\t\twords = []\n",
    "\t\t\n",
    "\t\twhile i < l:\n",
    "\t\t\tword = sent[i]\n",
    "\t\t\t\n",
    "\t\t\tif (word == 'not' or word == 'no' or word == 'never'  or word == 'nor' or word == 'neither') and i+1 < l:\n",
    "\t\t\t\tant = self.replace(sent[i+1])\n",
    "\t\t\t\t\n",
    "\t\t\t\tif ant:\n",
    "\t\t\t\t\twords.append(ant)\n",
    "\t\t\t\t\ti += 2\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\twords.append(word)\n",
    "\t\t\ti += 1\n",
    "\t\t\n",
    "\t\treturn words\n",
    "    \n",
    "replacer = AntonymReplacer()\n",
    "replacer.replace_negations([\"musn't\", 'antonym', 'uglify', 'our', 'ugly'])\n",
    "#replacer.replace('rarely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.125"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "#testimonial = TextBlob()\n",
    "#testimonial.sentiment\n",
    "\n",
    "def detect_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "\n",
    "filtered2 = filtered.copy()\n",
    "\n",
    "filtered2['polarity'] = filtered2.text.apply(detect_polarity)\n",
    "filtered2\n",
    "\n",
    "detect_polarity(\"The most infuriating!\")\n",
    "\n",
    "#davidim = filtered2.apply(TextBlob()).tolist()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizingSentance(sentence):\n",
    "    \n",
    "    global newStopWords\n",
    "    \n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    document = tokenizer.tokenize(sentence)\n",
    "    doc = spacy.tokens.Doc(nlp.vocab, words=document)\n",
    "    \n",
    "    result = \" \".join([token.lemma_ for token in doc if (token.lemma_.lower() not in stopwords) and (token.lemma_.lower() not in newStopWords) and (token.lemma_ != \"-PRON-\")])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentA = 'The man went out for a walk'\n",
    "documentB = 'the children sat around the fire'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>around</th>\n",
       "      <th>children</th>\n",
       "      <th>fire</th>\n",
       "      <th>for</th>\n",
       "      <th>man</th>\n",
       "      <th>out</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "      <th>walk</th>\n",
       "      <th>went</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303216</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.42616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.407401</td>\n",
       "      <td>0.407401</td>\n",
       "      <td>0.407401</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.407401</td>\n",
       "      <td>0.579739</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     around  children      fire      for      man      out       sat  \\\n",
       "0  0.000000  0.000000  0.000000  0.42616  0.42616  0.42616  0.000000   \n",
       "1  0.407401  0.407401  0.407401  0.00000  0.00000  0.00000  0.407401   \n",
       "\n",
       "        the     walk     went  \n",
       "0  0.303216  0.42616  0.42616  \n",
       "1  0.579739  0.00000  0.00000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([documentA, documentB])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the man went out for a walk', 'the children sat around the fire']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[documentA, documentB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
